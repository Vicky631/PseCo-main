{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!git clone --depth 1 https://github.com/Hzzone/PseCo\n",
    "import sys\n",
    "sys.path.insert(0, './PseCo')\n",
    "!nvidia-smi\n",
    "# make sure that GPU is used"
   ],
   "id": "c06fa0ac16e5378f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!python -m pip install detectron2==0.6 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n",
    "!pip install -r requirements.txt\n",
    "# import gdown\n",
    "# gdown.download_folder('https://drive.google.com/drive/folders/1RwxDPiL3dcUJc14arrvJkgTpI2XSddGF')"
   ],
   "id": "2896faae50cb9dad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.ops as vision_ops\n",
    "from ops.foundation_models.segment_anything.utils.amg import batched_mask_to_box\n",
    "from ops.ops import _nms, plot_results, convert_to_cuda\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "torch.cuda.set_device(0)\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "!gpustat"
   ],
   "id": "2147f4bb6a86b805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "project_root = './PseCo'",
   "id": "5a87c81a9e16c072"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def read_image(fname):\n",
    "    img = Image.open(f'{project_root}/data/fsc147/images_384_VarV2/{fname}')\n",
    "    transform = A.Compose([\n",
    "        A.LongestMaxSize(1024),\n",
    "        A.PadIfNeeded(1024, border_mode=0, position=A.PadIfNeeded.PositionType.TOP_LEFT),\n",
    "    ])\n",
    "    img = Image.fromarray(transform(image=np.array(img))['image'])\n",
    "    return img"
   ],
   "id": "e2842da1fc118240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ops.foundation_models.segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor, build_sam, build_sam_vit_b, build_sam_vit_h\n",
    "\n",
    "# sam = build_sam_vit_b().cuda().eval()\n",
    "sam = build_sam_vit_h().cuda().eval()"
   ],
   "id": "cb892ba5a6f361c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "clip_text_prompts = torch.load(f'{project_root}/data/fsc147/clip_text_prompt.pth', map_location='cpu')",
   "id": "5bf917f93772951a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_data = torch.load(f'{project_root}/data/fsc147/sam/all_data_vith.pth', map_location='cpu')\n",
    "all_predictions = torch.load(f'{project_root}/data/fsc147/sam/all_predictions_vith.pth', map_location='cpu')\n",
    "\n",
    "all_pseudo_boxes = torch.load(f'{project_root}/data/fsc147/sam/pseudo_boxes_data_vith.pth', map_location='cpu')"
   ],
   "id": "537a4e897f94670f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for fname in tqdm.tqdm(all_data):\n",
    "    target = all_data[fname]\n",
    "    target['image_id'] = fname\n",
    "    target['predictions'] = all_predictions[fname]\n",
    "    if all_data[fname]['split'] == 'train':\n",
    "        target['annotations']['boxes'] = all_pseudo_boxes[fname]['pred_boxes']\n",
    "        target['annotations']['ious'] = all_pseudo_boxes[fname]['pred_ious']\n",
    "all_image_list = {'train': [], 'val': [], 'test': [], 'all': []}\n",
    "for fname in all_data:\n",
    "    all_image_list[all_data[fname]['split']].append(fname)\n",
    "    all_image_list['all'].append(fname)"
   ],
   "id": "cffc3e5fd5844f09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fname = '22.jpg'\n",
    "plot_results(read_image(fname),\n",
    "bboxes=all_data[fname]['annotations']['boxes'],\n",
    "points=all_data[fname]['annotations']['points'],\n",
    "             )"
   ],
   "id": "1313046dc3c3c8ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from models import ROIHeadMLP as ROIHead\n",
    "cls_head = ROIHead().cuda().eval()\n",
    "# zeroshot\n",
    "# cls_head.load_state_dict(torch.load(f'{project_root}/data/fsc147/checkpoints/MLP_small_box_w1_zeroshot.tar', map_location='cpu')['cls_head'])\n",
    "# fewshot\n",
    "cls_head.load_state_dict(torch.load(f'{project_root}/data/fsc147/checkpoints/MLP_small_box_w1_fewshot.tar', map_location='cpu')['cls_head'])"
   ],
   "id": "7dbbcad11c332764"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "display(all_data[fname]['split'])\n",
    "display(all_data[fname]['class_name'])\n",
    "_ = cls_head.eval()\n",
    "annotations = all_data[fname]['annotations']\n",
    "gt_points = annotations['points']\n",
    "with torch.no_grad():\n",
    "    # zero-shot\n",
    "    # example_features = clip_text_prompts[all_data[fname]['class_name']].unsqueeze(0).cuda()\n",
    "    # few-shot\n",
    "    example_features = all_data[fname]['example_clip_features'].cuda()\n",
    "    min_scores = 0.05\n",
    "    max_points = 1000\n",
    "    pred_points_score = all_data[fname]['predictions']['pred_points_score']\n",
    "    mask = torch.zeros(pred_points_score.size(0))\n",
    "    mask[:min(pred_points_score.size(0), max_points)] = 1\n",
    "    mask[pred_points_score < min_scores] = 0\n",
    "    pred_boxes = all_data[fname]['predictions']['pred_boxes'][mask.bool()].cuda()\n",
    "    pred_ious = all_data[fname]['predictions']['pred_ious'][mask.bool()].cuda()\n",
    "    cls_outs = []\n",
    "    for indices in torch.arange(len(pred_boxes)).split(128):\n",
    "        cls_outs_ = cls_head(all_data[fname]['features'].cuda(), [pred_boxes[indices], ], [example_features, ] * len(indices))\n",
    "        pred_logits = cls_outs_.sigmoid().view(-1, len(example_features), 5).mean(1)\n",
    "        pred_logits = pred_logits * pred_ious[indices]\n",
    "        cls_outs.append(pred_logits)\n",
    "    cls_outs = torch.cat(cls_outs)\n",
    "    pred_boxes = pred_boxes[torch.arange(len(pred_boxes)), torch.argmax(cls_outs, dim=1)]\n",
    "    scores = cls_outs.max(1).values \n",
    "    indices = vision_ops.nms(pred_boxes, scores, 0.5)\n",
    "    pred_boxes = pred_boxes[indices]\n",
    "    scores = scores[indices]\n",
    "    pred_points = all_data[fname]['predictions']['pred_points'][mask.bool()].cuda()[indices]\n",
    "plt.figure(figsize=(10,10))\n",
    "COLORS = [[0.000, 0.447, 0.741], ]\n",
    "h, w = all_data[fname]['height'], all_data[fname]['width']\n",
    "scale = 1024 / max(h, w)\n",
    "plt.imshow(read_image(fname))\n",
    "for p, (xmin, ymin, xmax, ymax), c in zip(scores, pred_boxes.tolist(), COLORS * len(pred_boxes)):\n",
    "    if p < 0.1:\n",
    "        continue\n",
    "    plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                               fill=False, color=c,\n",
    "                               linewidth=2.0,\n",
    "                               ))\n",
    "    text = f'{int(p*100)}%'\n",
    "    plt.gca().text(xmin, ymin, text,\n",
    "            fontsize=5,\n",
    "            bbox=dict(facecolor='yellow',\n",
    "                      boxstyle='square,pad=.25',\n",
    "                      alpha=0.5)\n",
    "            )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "9f41c491ad5e2de3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b5297d5eecff98ad"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
